{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10. 케라스를 사용한 인공 신경망 소개"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 생물학적 뉴런에서 인공 뉴런까지"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # 꽃잎의 길이와 너비\n",
    "y = (iris.target == 0).astype(np.int) # 부채붓꽃(Iris Setosa)인가?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 케라스로 다층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.keras 에서 구현된 케라스 API 버젼 -tf 접미사는 tf.keras가 텐서플로 특화된 기능이 추가되어 케라스 API를 구현했다는 것을 나타냄\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스를 사용해 데이터셋 적재하기\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib.pyplot 의 imshow() 함수와 'binary' 컬러맵을 사용해 이미지 출력  가능\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~9 까지 클래스 아이디\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 이미지는 코트\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀셜 API를 사용해 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x24e8440bcd0>,\n",
       " <keras.layers.core.dense.Dense at 0x24e8440b2e0>,\n",
       " <keras.layers.core.dense.Dense at 0x24ed2082d60>,\n",
       " <keras.layers.core.dense.Dense at 0x24ec5f8a7f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_1 = model.layers[1]\n",
    "hidden_1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00900263,  0.04272863, -0.04711238, ..., -0.05374917,\n",
       "        -0.00437523, -0.04172974],\n",
       "       [-0.00654906,  0.01875776, -0.06586118, ...,  0.04730989,\n",
       "        -0.05571219,  0.0548614 ],\n",
       "       [ 0.04404957,  0.03006719,  0.06051371, ..., -0.01007503,\n",
       "         0.01528049, -0.06216595],\n",
       "       ...,\n",
       "       [ 0.03087259,  0.01648729, -0.06382301, ...,  0.04749279,\n",
       "        -0.06610171,  0.02856842],\n",
       "       [-0.00807952,  0.05528942, -0.02437977, ...,  0.01897026,\n",
       "         0.03872108,  0.06538887],\n",
       "       [-0.01073142,  0.06068146, -0.04091919, ...,  0.04069037,\n",
       "         0.04296832, -0.04729627]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden_1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "            optimizer = 'sgd',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.7238 - accuracy: 0.7623 - val_loss: 0.5201 - val_accuracy: 0.8270\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4897 - accuracy: 0.8292 - val_loss: 0.4711 - val_accuracy: 0.8332\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4463 - accuracy: 0.8425 - val_loss: 0.4339 - val_accuracy: 0.8558\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4183 - accuracy: 0.8519 - val_loss: 0.4272 - val_accuracy: 0.8584\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3975 - accuracy: 0.8607 - val_loss: 0.4102 - val_accuracy: 0.8542\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3835 - accuracy: 0.8642 - val_loss: 0.3703 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3687 - accuracy: 0.8693 - val_loss: 0.3816 - val_accuracy: 0.8652\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3579 - accuracy: 0.8722 - val_loss: 0.3573 - val_accuracy: 0.8772\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3465 - accuracy: 0.8773 - val_loss: 0.3543 - val_accuracy: 0.8714\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3363 - accuracy: 0.8787 - val_loss: 0.3607 - val_accuracy: 0.8674\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3286 - accuracy: 0.8829 - val_loss: 0.3615 - val_accuracy: 0.8694\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8854 - val_loss: 0.3325 - val_accuracy: 0.8778\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8878 - val_loss: 0.3375 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8907 - val_loss: 0.3286 - val_accuracy: 0.8800\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2984 - accuracy: 0.8914 - val_loss: 0.3235 - val_accuracy: 0.8814\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8943 - val_loss: 0.3495 - val_accuracy: 0.8756\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2867 - accuracy: 0.8967 - val_loss: 0.3217 - val_accuracy: 0.8820\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2795 - accuracy: 0.8997 - val_loss: 0.3344 - val_accuracy: 0.8816\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2761 - accuracy: 0.9001 - val_loss: 0.3207 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2713 - accuracy: 0.9029 - val_loss: 0.3116 - val_accuracy: 0.8868\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2657 - accuracy: 0.9036 - val_loss: 0.3229 - val_accuracy: 0.8826\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2601 - accuracy: 0.9064 - val_loss: 0.3093 - val_accuracy: 0.8858\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2569 - accuracy: 0.9071 - val_loss: 0.3053 - val_accuracy: 0.8884\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2517 - accuracy: 0.9092 - val_loss: 0.3031 - val_accuracy: 0.8918\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2484 - accuracy: 0.9103 - val_loss: 0.3018 - val_accuracy: 0.8892\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2430 - accuracy: 0.9127 - val_loss: 0.3372 - val_accuracy: 0.8792\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2405 - accuracy: 0.9136 - val_loss: 0.2975 - val_accuracy: 0.8926\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2355 - accuracy: 0.9151 - val_loss: 0.3042 - val_accuracy: 0.8910\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2311 - accuracy: 0.9163 - val_loss: 0.3003 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2282 - accuracy: 0.9180 - val_loss: 0.3015 - val_accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # 수직축 범위를 [0-1] 사이로 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3328465521335602, 0.881600022315979]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 예측한 정답\n",
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[np.argmax(y_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 정답\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀셜 API를 사용해 회귀용 다층 퍼셉트론 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9844 - val_loss: 0.8635\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.5399\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4757 - val_loss: 0.5138\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 0.4949\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4665 - val_loss: 0.4840\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4708\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4245 - val_loss: 0.4899\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4176 - val_loss: 0.4568\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4115 - val_loss: 0.4522\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4484\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.4382\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4352\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4364\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4250\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4234\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4159\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.4218\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.4137\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.4094\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.4062\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3812\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # 새로운 샘플\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수형 API\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "# Sequential API\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#    keras.layers.Dense(300, activation='relu'),\n",
    "#    keras.layers.Dense(100, activation='relu'),\n",
    "#    keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30)           930         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 입력 다루기\n",
    "\n",
    "# 특성 0에서 4까지 5개의 특성을 와이드 경로에 보내고\n",
    "# 특성 2에서 7까지 6개의 특성을 딥 경로로 전달, 3개의 특성 (특성 2, 3, 4)는 양쪽에 모두 전달 됨\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.4818 - val_loss: 1.1341\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8815 - val_loss: 0.8086\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 0.7341\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6659 - val_loss: 0.6946\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6330 - val_loss: 0.6673\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6090 - val_loss: 0.6474\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5903 - val_loss: 0.6304\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5746 - val_loss: 0.6161\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5620 - val_loss: 0.6052\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5511 - val_loss: 0.5957\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5416 - val_loss: 0.5870\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5335 - val_loss: 0.5801\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.5759\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5682\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 0.5623\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5096 - val_loss: 0.5590\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5051 - val_loss: 0.5568\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 0.5509\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4974 - val_loss: 0.5488\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.5438\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5031\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제를 위한 보조 출력 추가하기\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 2.5238 - main_output_loss: 2.3991 - aux_output_loss: 3.6461 - val_loss: 1.2832 - val_main_output_loss: 1.0918 - val_aux_output_loss: 3.0055\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0219 - main_output_loss: 0.8601 - aux_output_loss: 2.4784 - val_loss: 0.9622 - val_main_output_loss: 0.8160 - val_aux_output_loss: 2.2779\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8405 - main_output_loss: 0.7154 - aux_output_loss: 1.9665 - val_loss: 0.8491 - val_main_output_loss: 0.7338 - val_aux_output_loss: 1.8865\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7621 - main_output_loss: 0.6603 - aux_output_loss: 1.6777 - val_loss: 0.7949 - val_main_output_loss: 0.6989 - val_aux_output_loss: 1.6588\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7169 - main_output_loss: 0.6295 - aux_output_loss: 1.5043 - val_loss: 0.7583 - val_main_output_loss: 0.6744 - val_aux_output_loss: 1.5131\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6871 - main_output_loss: 0.6083 - aux_output_loss: 1.3969 - val_loss: 0.7380 - val_main_output_loss: 0.6618 - val_aux_output_loss: 1.4236\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6647 - main_output_loss: 0.5915 - aux_output_loss: 1.3234 - val_loss: 0.7140 - val_main_output_loss: 0.6422 - val_aux_output_loss: 1.3599\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6475 - main_output_loss: 0.5786 - aux_output_loss: 1.2682 - val_loss: 0.6974 - val_main_output_loss: 0.6291 - val_aux_output_loss: 1.3123\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6332 - main_output_loss: 0.5674 - aux_output_loss: 1.2252 - val_loss: 0.6859 - val_main_output_loss: 0.6205 - val_aux_output_loss: 1.2742\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6205 - main_output_loss: 0.5574 - aux_output_loss: 1.1891 - val_loss: 0.6763 - val_main_output_loss: 0.6133 - val_aux_output_loss: 1.2436\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6098 - main_output_loss: 0.5489 - aux_output_loss: 1.1580 - val_loss: 0.6646 - val_main_output_loss: 0.6036 - val_aux_output_loss: 1.2132\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5994 - main_output_loss: 0.5404 - aux_output_loss: 1.1305 - val_loss: 0.6533 - val_main_output_loss: 0.5939 - val_aux_output_loss: 1.1879\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5911 - main_output_loss: 0.5339 - aux_output_loss: 1.1054 - val_loss: 0.6473 - val_main_output_loss: 0.5897 - val_aux_output_loss: 1.1653\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5830 - main_output_loss: 0.5275 - aux_output_loss: 1.0826 - val_loss: 0.6383 - val_main_output_loss: 0.5823 - val_aux_output_loss: 1.1428\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5757 - main_output_loss: 0.5218 - aux_output_loss: 1.0609 - val_loss: 0.6315 - val_main_output_loss: 0.5771 - val_aux_output_loss: 1.1209\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5687 - main_output_loss: 0.5162 - aux_output_loss: 1.0405 - val_loss: 0.6255 - val_main_output_loss: 0.5724 - val_aux_output_loss: 1.1028\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5623 - main_output_loss: 0.5113 - aux_output_loss: 1.0214 - val_loss: 0.6190 - val_main_output_loss: 0.5671 - val_aux_output_loss: 1.0857\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5566 - main_output_loss: 0.5070 - aux_output_loss: 1.0031 - val_loss: 0.6123 - val_main_output_loss: 0.5617 - val_aux_output_loss: 1.0675\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5510 - main_output_loss: 0.5027 - aux_output_loss: 0.9854 - val_loss: 0.6102 - val_main_output_loss: 0.5613 - val_aux_output_loss: 1.0502\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5460 - main_output_loss: 0.4990 - aux_output_loss: 0.9689 - val_loss: 0.6058 - val_main_output_loss: 0.5581 - val_aux_output_loss: 1.0345\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5549 - main_output_loss: 0.5077 - aux_output_loss: 0.9802\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # 표준 매개변수를 처리함 (예를 들어, name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 3.3682 - output_1_loss: 3.0897 - output_2_loss: 5.8746 - val_loss: 1.9422 - val_output_1_loss: 1.5068 - val_output_2_loss: 5.8610\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3370 - output_1_loss: 0.9428 - output_2_loss: 4.8851 - val_loss: 1.2022 - val_output_1_loss: 0.8431 - val_output_2_loss: 4.4346\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0281 - output_1_loss: 0.7344 - output_2_loss: 3.6720 - val_loss: 1.0103 - val_output_1_loss: 0.7509 - val_output_2_loss: 3.3442\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8938 - output_1_loss: 0.6807 - output_2_loss: 2.8125 - val_loss: 0.9048 - val_output_1_loss: 0.7134 - val_output_2_loss: 2.6274\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8031 - output_1_loss: 0.6418 - output_2_loss: 2.2549 - val_loss: 0.8286 - val_output_1_loss: 0.6793 - val_output_2_loss: 2.1721\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7413 - output_1_loss: 0.6125 - output_2_loss: 1.9007 - val_loss: 0.7730 - val_output_1_loss: 0.6499 - val_output_2_loss: 1.8803\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6963 - output_1_loss: 0.5878 - output_2_loss: 1.6730 - val_loss: 0.7318 - val_output_1_loss: 0.6259 - val_output_2_loss: 1.6848\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6636 - output_1_loss: 0.5684 - output_2_loss: 1.5208 - val_loss: 0.7041 - val_output_1_loss: 0.6093 - val_output_2_loss: 1.5568\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6383 - output_1_loss: 0.5515 - output_2_loss: 1.4197 - val_loss: 0.6818 - val_output_1_loss: 0.5949 - val_output_2_loss: 1.4645\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6186 - output_1_loss: 0.5377 - output_2_loss: 1.3466 - val_loss: 0.6649 - val_output_1_loss: 0.5835 - val_output_2_loss: 1.3973\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.6187 - output_1_loss: 0.5427 - output_2_loss: 1.3027\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024ED20ABB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2236 - val_loss: 1.1525\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8500 - val_loss: 0.7467\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6691 - val_loss: 0.6826\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6219 - val_loss: 0.6469\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5897 - val_loss: 0.6171\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5654 - val_loss: 0.5986\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5833\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5676\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 0.5550\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5028 - val_loss: 0.5474\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5021\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./keras/my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"./keras/my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024E89951D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.601483 ],\n",
       "       [1.8697193],\n",
       "       [3.9253507]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24ed95282e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"./keras/my_keras_weights.ckpt\")\n",
    "model.load_weights(\"./keras/my_keras_weights.ckpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1715 - val_loss: 1.0318\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7715 - val_loss: 0.7183\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6238 - val_loss: 0.6384\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5748 - val_loss: 0.6050\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5463 - val_loss: 0.5799\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5278 - val_loss: 0.5656\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5128 - val_loss: 0.5529\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 0.5442\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 0.5371\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4877 - val_loss: 0.5322\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4883\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./keras/my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"./keras/my_keras_model.h5\") # 최상의 모델로 롤백\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4805 - val_loss: 0.5274\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4765 - val_loss: 0.5216\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.5207\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4674 - val_loss: 0.5153\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4643 - val_loss: 0.5162\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.5114\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4584 - val_loss: 0.5080\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.5081\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.5046\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.5046\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4475 - val_loss: 0.5004\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4452 - val_loss: 0.4979\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4988\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4948\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.4918\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4914\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4355 - val_loss: 0.4884\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4884\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4859\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4835\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4821\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4807\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4790\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4256 - val_loss: 0.4778\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4776\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.4748\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4220 - val_loss: 0.4737\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4728\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4193 - val_loss: 0.4726\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4711\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4691\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4681\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4665\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4133 - val_loss: 0.4653\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4644\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4623\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4638\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4610\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.4593\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4593\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.4561\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.4569\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4036 - val_loss: 0.4552\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4026 - val_loss: 0.4539\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4017 - val_loss: 0.4523\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.4522\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3997 - val_loss: 0.4502\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4498\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4476\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.4487\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3962 - val_loss: 0.4461\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4457\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3940 - val_loss: 0.4437\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4428\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4421\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4419\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.4410\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4399\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4388\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4375\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.4374\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4360\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4345\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4341\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4336\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4316\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4314\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4299\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.4293\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4311\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4270\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4276\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4247\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4243\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.4231\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4225\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4225\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4206\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4210\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4193\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4190\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.4191\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4162\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.4171\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.4149\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.4156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.4144\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.4130\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3662 - val_loss: 0.4117\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.4132\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.4112\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.4099\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.4087\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4081\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.4094\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.4078\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.4063\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.4053\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.4048\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.4043\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3707\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/363 [===========================>..] - ETA: 0s - loss: 0.3601\n",
      "val/train: 1.12\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.4033\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서보드(TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_01_31-17_39_24'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7606 - val_loss: 0.8938\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7660 - val_loss: 0.7384\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6771 - val_loss: 0.6912\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6384 - val_loss: 0.6614\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6108 - val_loss: 0.6415\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5884 - val_loss: 0.6215\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5693 - val_loss: 0.6035\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5532 - val_loss: 0.5900\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 0.5783\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.5673\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.5597\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5068 - val_loss: 0.5501\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4983 - val_loss: 0.5431\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5357\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4830 - val_loss: 0.5306\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4760 - val_loss: 0.5238\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.5190\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5130\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4599 - val_loss: 0.5088\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4542 - val_loss: 0.5046\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.5007\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4972\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4941\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 0.4899\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4865\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4834\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4292 - val_loss: 0.4822\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4789\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4762\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4220 - val_loss: 0.4756\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard 실행  \n",
    "- 텐서보드 설치된 가상환경 활성화\n",
    "- 노트북 디렉토리로 이동하여 다음 명령 입력\n",
    "- tensorboard --logdir=./my_logs --port=6006  \n",
    "\n",
    "그다음 웹 브라우저를 열고 localhost:6006에 접속하면 텐서보드를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # 몇몇 랜덤 데이터\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # 32 * 32 RGB 이미지\n",
    "        tf.summary.image('my_images', images * step / 1000, step=step)\n",
    "        texts = [\"The step is\" + str(step), \"Its square is\", str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000)/48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 신경망 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1364 - val_loss: 0.7597\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6791 - val_loss: 0.6618\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5883 - val_loss: 0.5950\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.5590\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4984 - val_loss: 0.5296\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.5128\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5029\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 0.4979\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4898\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4893\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 0.4814\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4804\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4813\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4249 - val_loss: 0.4714\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4231 - val_loss: 0.4702\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4686\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4164 - val_loss: 0.4645\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.4609\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.4582\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4591\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4550\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4536\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4545\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4473\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 0.4496\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4612\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4427\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4401\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4405\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4373\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.4350\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.4350\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.4324\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4354\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.4310\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.4301\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.4298\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.4273\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.4283\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4242\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.4255\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4224\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.4250\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.4190\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4201\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.4197\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.4187\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.4257\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.4163\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3673 - val_loss: 0.4219\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.4142\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.4116\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.4140\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.4115\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.4157\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.4089\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.4089\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.4097\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.4087\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.4094\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.4065\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.4046\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.4041\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.4068\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.4022\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.4097\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.4045\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.4035\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.4001\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.4014\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3998\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3983\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3994\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.4176\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3956\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3980\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3922\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.4012\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3953\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3936\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3906\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.4057\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.4023\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3892\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3897\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3861\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3972\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3935\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3873\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3845\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.3853\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3869\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.3961\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.3873\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3845\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3843\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3857\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3835\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3900\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3614\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "            validation_data = (X_valid, y_valid),\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8399 - val_loss: 0.6266\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5227 - val_loss: 0.5344\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4602 - val_loss: 0.5524\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.4818\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4658\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4562\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.4419\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3796 - val_loss: 0.4407\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.4300\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4260\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.4301\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4187\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.4045\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.3946\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3957\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3873\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3897\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3945\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.3824\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3890\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3797\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3730\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3705\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3737\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3640\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3730\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.3616\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3538\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3061 - val_loss: 0.3895\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.3446\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3041 - val_loss: 0.3536\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3025 - val_loss: 0.3431\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.3685\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3021 - val_loss: 0.3640\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.3527\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.3685\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.3395\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.3542\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2962 - val_loss: 0.3376\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3310\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.3348\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.3435\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3345\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.3292\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.3593\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2867 - val_loss: 0.3231\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.3216\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.3241\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.3396\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.3419\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.3545\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.3287\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2786 - val_loss: 0.3234\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2770 - val_loss: 0.3202\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2783 - val_loss: 0.3381\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2790 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2760 - val_loss: 0.3204\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2721 - val_loss: 0.3174\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.3168\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.3209\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2694 - val_loss: 0.3205\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2690 - val_loss: 0.3240\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3239\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2728 - val_loss: 0.3256\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2728 - val_loss: 0.3120\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2673 - val_loss: 0.3226\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.3221\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2666 - val_loss: 0.3447\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2698 - val_loss: 0.3217\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2654 - val_loss: 0.3366\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2669 - val_loss: 0.3183\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.3108\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2640 - val_loss: 0.3166\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2635 - val_loss: 0.3174\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2655 - val_loss: 0.3250\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2640 - val_loss: 0.3247\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2679 - val_loss: 0.3155\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.3520\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.3312\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2630 - val_loss: 0.3119\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.3296\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.3585\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4613\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0291 - val_loss: 0.6087\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5402\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4622 - val_loss: 0.4970\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4645\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4482\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3818 - val_loss: 0.4326\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.4487\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4204\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4127\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4082\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3932\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.3995\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.3933\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.3782\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3846\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3735\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3276 - val_loss: 0.3627\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3276 - val_loss: 0.3625\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3666\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3211 - val_loss: 0.3570\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3167 - val_loss: 0.3736\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3749\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3498\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.3377\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3158 - val_loss: 0.3464\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3078 - val_loss: 0.3640\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3343\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3017 - val_loss: 0.3407\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.3561\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3377\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2971 - val_loss: 0.3434\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2953 - val_loss: 0.3354\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2943 - val_loss: 0.3425\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.3251\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.3252\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.3346\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2897 - val_loss: 0.3450\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.3295\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2871 - val_loss: 0.3316\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3290\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2848 - val_loss: 0.3200\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.3199\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.3305\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2786 - val_loss: 0.3182\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2794 - val_loss: 0.3098\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.3523\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2776 - val_loss: 0.3121\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2784 - val_loss: 0.3217\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.3292\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2757 - val_loss: 0.3224\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3113\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3166\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2738 - val_loss: 0.3114\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2728 - val_loss: 0.3190\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2694 - val_loss: 0.3209\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3195\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9144 - val_loss: 0.5930\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 0.5013\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.4739\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4288 - val_loss: 0.4607\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4582\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4351\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.4393\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4291\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4446\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.4211\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4032\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3935\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.3995\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3833\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.3877\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3893\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.3817\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3718\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.3757\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3999\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3717\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3732\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3181 - val_loss: 0.3564\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3528\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3153 - val_loss: 0.3482\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.3472\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.3388\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3067 - val_loss: 0.3653\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3540\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3010 - val_loss: 0.3492\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3294\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.3573\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.3421\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.3546\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2942 - val_loss: 0.3299\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2911 - val_loss: 0.3334\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2905 - val_loss: 0.3413\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.3573\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2891 - val_loss: 0.3356\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.3544\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.3287\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.3180\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.3410\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.3218\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.3245\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.3312\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2745 - val_loss: 0.3105\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2773 - val_loss: 0.3379\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2757 - val_loss: 0.3254\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.3149\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2755 - val_loss: 0.3194\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2730 - val_loss: 0.3260\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2745 - val_loss: 0.3067\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2703 - val_loss: 0.3095\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2747 - val_loss: 0.3148\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2725 - val_loss: 0.3189\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2695 - val_loss: 0.3363\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2695 - val_loss: 0.3073\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2645 - val_loss: 0.3258\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2678 - val_loss: 0.3120\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2677 - val_loss: 0.3041\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2692 - val_loss: 0.3132\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2642 - val_loss: 0.3038\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.3280\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2658 - val_loss: 0.3060\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.3097\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2621 - val_loss: 0.3001\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.3170\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2637 - val_loss: 0.3511\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2637 - val_loss: 0.3317\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2622 - val_loss: 0.3126\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.3049\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.3131\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.3073\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.3142\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2546 - val_loss: 0.3202\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2547 - val_loss: 0.3100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2896\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8062 - val_loss: 0.5690\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5127 - val_loss: 0.5447\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4519 - val_loss: 0.5644\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.7662\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.6617\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4228 - val_loss: 0.7587\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 1.5363\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4447 - val_loss: 0.9441\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 1.0689\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 1.1705\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 1.2366\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 1.3359\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.2887\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.4580 - val_loss: 705.6629\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.0891 - val_loss: 0.5731\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4734 - val_loss: 0.4582\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4471\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4622 - val_loss: 0.4267\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4630\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4054 - val_loss: 0.4101\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.4181\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4378\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3804 - val_loss: 0.4078\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3935\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.4014\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3996\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.3926\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3909\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.3875\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.5826\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3821\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.3965\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4927\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.3849\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3781\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3399 - val_loss: 0.3895\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3811\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3830\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3745\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3827\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3867\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3495 - val_loss: 0.3827\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.3771\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3770\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3323 - val_loss: 0.3662\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3711\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3614\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3988\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.3772\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3778\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3296 - val_loss: 0.4007\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.3630\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3217 - val_loss: 0.3668\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.3651\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3672\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3745\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3672\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3453\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 49.4712 - val_loss: 1.7363\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4855 - val_loss: 0.8793\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 8.0552 - val_loss: 0.5591\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0309 - val_loss: 0.6290\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5382 - val_loss: 0.5572\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.5430\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5159 - val_loss: 0.5856\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4830 - val_loss: 0.5170\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4497 - val_loss: 0.5035\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4343 - val_loss: 0.4962\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4960\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.5048\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4977\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.5110\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.5053\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.5044\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.5028\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.5039\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.5188\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.5178\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.5285\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9417\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0422 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5992 - val_loss: 0.5868\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5147 - val_loss: 0.5395\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4720 - val_loss: 0.5102\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4475 - val_loss: 0.4892\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.4734\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4674\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 0.4651\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4425\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4438\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.4330\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3904 - val_loss: 0.4383\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4332\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4242\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.4229\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.4306\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4164\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3798 - val_loss: 0.4202\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4135\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4126\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.4045\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4135\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.4025\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4043\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3995\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3970\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.4020\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.3917\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.3979\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.3918\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.3897\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3864\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3419 - val_loss: 0.3837\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3870\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.3898\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3843\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3391 - val_loss: 0.3791\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3776\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.3749\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3727\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3708\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3306 - val_loss: 0.3666\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3637\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3751\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.3676\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3644\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3377 - val_loss: 0.3657\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3235 - val_loss: 0.3563\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3218 - val_loss: 0.3622\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3577\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3639\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3198 - val_loss: 0.3578\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3553\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3696\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3546\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3550\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3520\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3549\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.3476\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3540\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.3509\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3511\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3179 - val_loss: 0.3533\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3464\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3083 - val_loss: 0.3468\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.3434\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.3446\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.3504\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.3459\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3106 - val_loss: 0.3548\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3073 - val_loss: 0.3405\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3424\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3035 - val_loss: 0.3582\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3053 - val_loss: 0.3413\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.3423\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3416\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3460\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3032 - val_loss: 0.3377\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3021 - val_loss: 0.3366\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3019 - val_loss: 0.3333\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.3553\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3010 - val_loss: 0.3378\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.3345\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.3327\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2996 - val_loss: 0.3362\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2986 - val_loss: 0.3428\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2974 - val_loss: 0.3348\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3360\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2974 - val_loss: 0.3316\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2968 - val_loss: 0.3438\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2949 - val_loss: 0.3344\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2962 - val_loss: 0.3358\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2943 - val_loss: 0.3372\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3287\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2924 - val_loss: 0.3315\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3280\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.3270\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3217\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9607 - val_loss: 0.6265\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5452 - val_loss: 0.5498\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4918 - val_loss: 0.5185\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4652 - val_loss: 0.5050\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4516 - val_loss: 0.4928\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4825\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4349 - val_loss: 0.4734\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.4718\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4635\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4568\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4557\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4478\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4430\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.4330\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4360\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4251\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4206\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4238\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4132\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4203\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4248\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.4076\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4063\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.3998\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.4041\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3627 - val_loss: 0.4005\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3991\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3928\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3927\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3874\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3925\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.3959\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.3854\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3851\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.3819\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4002\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3826\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3765\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.3885\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3430 - val_loss: 0.3939\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.3840\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3773\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.3798\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3712\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3851\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3685\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3738\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3772\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3715\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3700\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3710\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3700\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3314 - val_loss: 0.3812\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3703\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3675\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.3702\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.3614\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3645\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3661\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3627\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3610\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3590\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3681\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3211 - val_loss: 0.3685\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3205 - val_loss: 0.3592\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3187 - val_loss: 0.3675\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3621\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3569\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3181 - val_loss: 0.3547\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3201 - val_loss: 0.3683\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3607\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3601\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3563\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3531\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.3510\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3612\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3665\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3126 - val_loss: 0.3478\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3473\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3535\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3115 - val_loss: 0.3477\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3466\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3536\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3478\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3078 - val_loss: 0.3510\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.3512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.3504\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3084 - val_loss: 0.3463\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3072 - val_loss: 0.3472\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.3537\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3058 - val_loss: 0.3489\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3072 - val_loss: 0.3403\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3050 - val_loss: 0.3451\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.3464\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3058 - val_loss: 0.3566\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3065 - val_loss: 0.3395\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3025 - val_loss: 0.3406\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3442\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.3445\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3178\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0368 - val_loss: 0.9081\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6197 - val_loss: 0.6513\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5538 - val_loss: 0.5718\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5100 - val_loss: 0.5417\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4888 - val_loss: 0.5261\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4678 - val_loss: 0.5177\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4598 - val_loss: 0.5085\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.5046\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.5017\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.5068\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4304 - val_loss: 0.5083\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.5090\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.5342\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4214 - val_loss: 0.5163\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4130 - val_loss: 0.5751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.5287\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.5354\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.5476\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.5593\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0573\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2483 - val_loss: 0.7155\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6160 - val_loss: 0.6327\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5585 - val_loss: 0.5767\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4981 - val_loss: 0.5416\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5175 - val_loss: 0.5341\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4613 - val_loss: 0.5107\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.5000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4937\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4885\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.4835\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4866\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4836\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4742\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4162 - val_loss: 0.4694\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4130 - val_loss: 0.4705\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4706\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4613\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4054 - val_loss: 0.4604\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4601\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.4597\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 0.4531\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4508\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.4511\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4072 - val_loss: 0.4490\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4426\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 0.4431\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4412\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3871 - val_loss: 0.4419\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.4365\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.4353\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.4352\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4306\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4290\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4316\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.4312\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4311\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4310\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4256\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4229\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4299\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3755 - val_loss: 0.4223\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.4201\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.4176\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.4238\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4166\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.4152\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3641 - val_loss: 0.4120\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.4127\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.4121\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.4150\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.4115\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.4150\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.4060\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.4033\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.4053\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.4118\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.4013\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.4031\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3994\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.4007\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3989\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3958\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.3998\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.4075\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.3967\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3983\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.3901\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.4009\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3922\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3927\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3925\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3892\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3884\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3910\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.3858\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3388 - val_loss: 0.4128\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3406 - val_loss: 0.3849\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.4175\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.3890\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3817\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3925\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.3846\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3798\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3867\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3771\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3323 - val_loss: 0.3795\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3758\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.3757\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3801\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3741\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.3746\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3766\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3765\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3735\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3682\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3690\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3684\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3696\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3288 - val_loss: 0.3693\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3800\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3496\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1788 - val_loss: 0.7327\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7000 - val_loss: 0.6482\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5947 - val_loss: 0.5929\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5385 - val_loss: 0.5591\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5120 - val_loss: 0.5390\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5258\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 0.5207\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4726 - val_loss: 0.5113\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.5055\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.4960\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4541 - val_loss: 0.4918\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4454 - val_loss: 0.4855\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.4892\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4397 - val_loss: 0.4779\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4755\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.4763\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4266 - val_loss: 0.4667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4229 - val_loss: 0.4655\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.4647\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4633\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4594\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4130 - val_loss: 0.4545\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4101 - val_loss: 0.4500\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4478\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4055 - val_loss: 0.4474\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4460\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4426\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4416\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4402\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4360\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4388\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4332\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.4282\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3883 - val_loss: 0.4299\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4301\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4286\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.4195\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.4241\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4168\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.4167\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4176\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3752 - val_loss: 0.4115\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3862 - val_loss: 0.4207\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4096\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4120\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.4049\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.4066\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.4062\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3662 - val_loss: 0.4089\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.4035\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4037\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.4006\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.3999\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3985\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3943\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.3951\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.4007\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3913\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.4562\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3938\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3902\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3948\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3867\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3900\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3877\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3940\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3826\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3849\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.3893\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3931\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3794\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.3918\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3953\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3802\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.3763\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3856\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.3776\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3752\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3749\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3865\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.3709\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3917\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3817\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3713\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.3767\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3771\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3693\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3748\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3692\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3325 - val_loss: 0.3713\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3667\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3918\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.3716\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3692\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.6878\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3670\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3818\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3620\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3668\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3722\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3417\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9707 - val_loss: 0.6749\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5522 - val_loss: 0.5759\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4947 - val_loss: 0.5433\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4849 - val_loss: 0.5191\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4618 - val_loss: 0.5216\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4413 - val_loss: 0.5114\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.5105\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.5697\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.5352\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.5466\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4527 - val_loss: 1.0361\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5657 - val_loss: 0.5441\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.5441\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.5584\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.5784\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3995 - val_loss: 0.6003\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.6143\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6842\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7837 - val_loss: 0.8311\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0562 - val_loss: 0.5747\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6119 - val_loss: 0.4901\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4717\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.4827\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4295 - val_loss: 0.4883\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.4486\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4362\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3872 - val_loss: 0.4341\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.4263\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.4418\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.4266\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4163\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4261\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3688 - val_loss: 0.4151\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.4133\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.4063\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.4030\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3606 - val_loss: 0.4009\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.4020\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.4588\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4898 - val_loss: 0.4164\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.4136\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.4113\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.4049\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.4004\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.4061\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3961\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3923\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.3933\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3917\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3937\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3852\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3887\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3867\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3843\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3878\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3862\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3812\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3935\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3804\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3830\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 0.3750\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3282 - val_loss: 0.3739\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3734\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3763\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3934\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3784\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3710\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3278 - val_loss: 0.3733\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3790\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.3681\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3690\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3731\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.3628\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.3598\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3621\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3154 - val_loss: 0.3699\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3622\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3580\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3595\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3558\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.3613\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3106 - val_loss: 0.3560\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3558\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3525\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3537\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3091 - val_loss: 0.3503\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 0.3591\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3054 - val_loss: 0.3636\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3517\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3482\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3037 - val_loss: 0.3493\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3032 - val_loss: 0.3550\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.3466\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3456\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3624\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3460\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3527\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.3574\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3503\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.3512\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.3491\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3071 - val_loss: 0.3546\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3426\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3012 - val_loss: 0.3739\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3440\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.3461\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2991 - val_loss: 0.3495\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3012 - val_loss: 0.3547\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2969 - val_loss: 0.3404\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2964 - val_loss: 0.3418\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2967 - val_loss: 0.3461\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2965 - val_loss: 0.3548\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2956 - val_loss: 0.3406\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2941 - val_loss: 0.3371\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2946 - val_loss: 0.3401\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2930 - val_loss: 0.3417\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2924 - val_loss: 0.3339\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2940 - val_loss: 0.3374\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3265\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1144 - val_loss: 4.8115\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.9156 - val_loss: 5.2360\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1751 - val_loss: 3.7961\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0301 - val_loss: 2.8377\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2692 - val_loss: 2.1924\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7543\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4136 - val_loss: 1.4545\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1784 - val_loss: 1.2469\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0171 - val_loss: 1.1026\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9058 - val_loss: 1.0014\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8283 - val_loss: 0.9289\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7739 - val_loss: 0.8772\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7352 - val_loss: 0.8395\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7073 - val_loss: 0.8112\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6869 - val_loss: 0.7900\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6716 - val_loss: 0.7738\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6598 - val_loss: 0.7609\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6506 - val_loss: 0.7504\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.7416\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.7343\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.7279\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6269 - val_loss: 0.7221\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.7170\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.7121\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.7076\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6121 - val_loss: 0.7034\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6090 - val_loss: 0.6995\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6060 - val_loss: 0.6957\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6032 - val_loss: 0.6920\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6886\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 0.6852\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.6821\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5929 - val_loss: 0.6790\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6760\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5883 - val_loss: 0.6731\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5861 - val_loss: 0.6703\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6676\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5819 - val_loss: 0.6650\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5799 - val_loss: 0.6624\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5779 - val_loss: 0.6599\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5761 - val_loss: 0.6575\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5742 - val_loss: 0.6551\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5725 - val_loss: 0.6528\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5707 - val_loss: 0.6505\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5691 - val_loss: 0.6483\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5675 - val_loss: 0.6462\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5659 - val_loss: 0.6441\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5644 - val_loss: 0.6420\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5629 - val_loss: 0.6401\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 0.6382\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5601 - val_loss: 0.6363\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5587 - val_loss: 0.6345\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.6327\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5561 - val_loss: 0.6310\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 0.6293\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5537 - val_loss: 0.6276\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5526 - val_loss: 0.6260\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5514 - val_loss: 0.6245\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5503 - val_loss: 0.6230\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5493 - val_loss: 0.6215\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5482 - val_loss: 0.6201\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5472 - val_loss: 0.6187\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5463 - val_loss: 0.6173\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.6160\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5444 - val_loss: 0.6147\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 0.6135\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5427 - val_loss: 0.6122\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5418 - val_loss: 0.6110\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.6099\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5402 - val_loss: 0.6088\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.6077\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.6066\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5380 - val_loss: 0.6055\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.6045\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.6035\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5359 - val_loss: 0.6026\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.6016\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5347 - val_loss: 0.6008\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5999\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.5991\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5329 - val_loss: 0.5983\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 0.5973\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 0.5965\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5312 - val_loss: 0.5957\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5307 - val_loss: 0.5950\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5302 - val_loss: 0.5943\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5297 - val_loss: 0.5935\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5292 - val_loss: 0.5929\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.5923\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5915\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5279 - val_loss: 0.5909\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.5902\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5271 - val_loss: 0.5897\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5266 - val_loss: 0.5890\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5262 - val_loss: 0.5884\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5877\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 0.5872\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5251 - val_loss: 0.5867\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5248 - val_loss: 0.5861\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5244 - val_loss: 0.5857\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.5853\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5583\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.3891 - val_loss: 5.7528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9446 - val_loss: 4.0199\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4368 - val_loss: 2.9262\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4865 - val_loss: 2.2150\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8725 - val_loss: 1.7415\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4673 - val_loss: 1.4211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1977 - val_loss: 1.2012\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0153 - val_loss: 1.0486\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8911 - val_loss: 0.9417\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8055 - val_loss: 0.8661\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7461 - val_loss: 0.8119\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7044 - val_loss: 0.7729\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6748 - val_loss: 0.7443\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6535 - val_loss: 0.7231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6378 - val_loss: 0.7072\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6262 - val_loss: 0.6949\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 0.6851\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6102 - val_loss: 0.6775\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6044 - val_loss: 0.6710\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.6655\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5955 - val_loss: 0.6608\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.6568\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5887 - val_loss: 0.6531\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5857 - val_loss: 0.6498\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5829 - val_loss: 0.6468\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5804 - val_loss: 0.6439\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5779 - val_loss: 0.6413\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 0.6388\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5733 - val_loss: 0.6364\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 0.6342\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - val_loss: 0.6321\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5671 - val_loss: 0.6300\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.6281\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.6262\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5615 - val_loss: 0.6244\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5598 - val_loss: 0.6227\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5581 - val_loss: 0.6210\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - val_loss: 0.6194\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 0.6179\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5533 - val_loss: 0.6164\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5518 - val_loss: 0.6150\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5504 - val_loss: 0.6136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.6123\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.6110\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5463 - val_loss: 0.6097\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.6085\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.6074\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 0.6063\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 0.6052\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.6042\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 0.6032\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.6022\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.6012\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.6002\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.5994\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5986\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.5978\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5325 - val_loss: 0.5970\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 0.5962\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.5955\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.5948\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 0.5942\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 0.5934\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.5928\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5271 - val_loss: 0.5921\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5916\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5911\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5905\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5899\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5895\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5890\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5886\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5880\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.5876\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5871\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5868\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.5865\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.5860\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5857\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5189 - val_loss: 0.5854\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5849\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5847\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5177 - val_loss: 0.5845\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5173 - val_loss: 0.5840\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5838\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5165 - val_loss: 0.5835\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5162 - val_loss: 0.5833\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.5830\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.5826\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5825\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5821\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5818\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 0.5816\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.5814\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5813\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5135 - val_loss: 0.5811\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 0.5810\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5130 - val_loss: 0.5809\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 0.5808\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5125 - val_loss: 0.5807\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5368\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.3982 - val_loss: 4.5716\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7507 - val_loss: 3.2909\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6916 - val_loss: 2.4453\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0012 - val_loss: 1.8769\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5412 - val_loss: 1.4894\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2309 - val_loss: 1.2228\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0197 - val_loss: 1.0373\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8744 - val_loss: 0.9075\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7738 - val_loss: 0.8160\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7037 - val_loss: 0.7512\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.7049\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.6716\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5952 - val_loss: 0.6477\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5778 - val_loss: 0.6303\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.6177\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - val_loss: 0.6083\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5497 - val_loss: 0.6014\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 0.5961\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.5922\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5387 - val_loss: 0.5893\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5367 - val_loss: 0.5869\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.5851\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5836\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5329 - val_loss: 0.5824\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.5814\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 0.5806\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.5799\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.5793\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5788\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.5783\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.5779\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.5776\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.5772\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.5769\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 0.5765\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5763\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.5760\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5271 - val_loss: 0.5758\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5755\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5753\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.5751\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 0.5748\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5745\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 0.5743\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5254 - val_loss: 0.5741\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5739\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.5737\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.5735\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 0.5733\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5731\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.5729\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5727\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5726\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.5724\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5236 - val_loss: 0.5723\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5721\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.5719\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5718\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 0.5717\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5715\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5714\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5226 - val_loss: 0.5713\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5711\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5710\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5709\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5220 - val_loss: 0.5707\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5706\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5705\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.5704\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 0.5702\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5701\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.5700\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5699\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5699\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.5697\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5696\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5208 - val_loss: 0.5695\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5695\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5206 - val_loss: 0.5694\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 0.5693\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 0.5693\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5691\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5691\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.5690\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5688\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 0.5687\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5687\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5687\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.5687\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5686\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5685\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5685\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5195 - val_loss: 0.5684\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 0.5683\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 0.5682\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5681\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5680\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 0.5679\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5191 - val_loss: 0.5679\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5191 - val_loss: 0.5678\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5221\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0762 - val_loss: 0.7029\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5662 - val_loss: 0.6209\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5831\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5709\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5592 - val_loss: 0.5743\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5628 - val_loss: 0.5818\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5964\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5683 - val_loss: 0.6192\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5559 - val_loss: 0.6452\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 0.6962\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5637 - val_loss: 0.7195\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5509 - val_loss: 0.7672\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.6672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.8647\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6624\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.0353 - val_loss: 10.5018\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 23.8710 - val_loss: 355.6095\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7837.2676 - val_loss: 12996.2656\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 158888.0625 - val_loss: 460605.5938\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1193621.2500 - val_loss: 16545538.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 38875416.0000 - val_loss: 595707584.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12772873216.0000 - val_loss: 21009281024.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 628018053120.0000 - val_loss: 751618162688.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 41349206245376.0000 - val_loss: 26838629875712.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 72810986733568.0000 - val_loss: 966166516334592.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 21762225626677248.0000 - val_loss: 35588328795406336.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 431024429334528.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7410 - val_loss: 10.7881\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 22.2334 - val_loss: 358.7934\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8271.0439 - val_loss: 12868.7676\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 32567.8008 - val_loss: 467639.5000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1119589.1250 - val_loss: 17179670.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 931212480.0000 - val_loss: 604632192.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1299401728.0000 - val_loss: 22003558400.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 281027870720.0000 - val_loss: 797910171648.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 44042377232384.0000 - val_loss: 28823693295616.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 366222868742144.0000 - val_loss: 1047936385417216.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 23584410599161856.0000 - val_loss: 37697258669473792.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 364772478418944.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8433 - val_loss: 0.5805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5764 - val_loss: 0.8042\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4282 - val_loss: 0.7869\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.8064\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.8207\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.8114\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.8291\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.8363\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.8489\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.8410\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.8958\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.0204\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7743 - val_loss: 0.5963\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6051 - val_loss: 0.4953\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.4730\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4499\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4421\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.4226\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.4002\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.3956\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.4180\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3952\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3747\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3732\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3644\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3272 - val_loss: 0.3573\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3800\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3500\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3573\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3142 - val_loss: 0.3449\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3578\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.3548\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3056 - val_loss: 0.3595\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3613\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.3404\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3298\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3004 - val_loss: 0.3384\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2968 - val_loss: 0.3426\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.3332\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2936 - val_loss: 0.3805\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2930 - val_loss: 0.3514\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2890 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.3360\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.3212\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2842 - val_loss: 0.3247\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.3286\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2840 - val_loss: 0.3289\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.3128\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2800 - val_loss: 0.3527\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2788 - val_loss: 0.3198\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2791 - val_loss: 0.3324\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2743 - val_loss: 0.3138\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2729 - val_loss: 0.3292\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2779 - val_loss: 0.3098\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2769 - val_loss: 0.3259\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2741 - val_loss: 0.3011\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.3039\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2692 - val_loss: 0.3169\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3102\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3093\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.3018\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2662 - val_loss: 0.3291\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2668 - val_loss: 0.3188\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2699 - val_loss: 0.3035\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2667 - val_loss: 0.3156\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2650 - val_loss: 0.3063\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3028\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2283 - val_loss: 0.7230\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5895 - val_loss: 0.6070\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5675\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5088 - val_loss: 0.5436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4919 - val_loss: 0.5299\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4785 - val_loss: 0.5279\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4727 - val_loss: 0.5165\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4629 - val_loss: 0.5086\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.5074\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4567 - val_loss: 0.5021\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4522 - val_loss: 0.5043\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4968\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4959\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4464 - val_loss: 0.4943\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4873\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4877\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4364 - val_loss: 0.4845\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4316 - val_loss: 0.4805\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4816\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4782\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4785\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4788\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4757\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.4770\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4759\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.4842\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4165 - val_loss: 0.4763\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4147 - val_loss: 0.4765\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4157 - val_loss: 0.4794\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4116 - val_loss: 0.4772\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.4911\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4090 - val_loss: 0.4830\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4808\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5344\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2078 - val_loss: 0.7175\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6320 - val_loss: 0.6252\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.5682\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5087 - val_loss: 0.5357\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4870 - val_loss: 0.5232\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4724 - val_loss: 0.5143\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4616 - val_loss: 0.5107\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4591 - val_loss: 0.4942\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.4948\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4453 - val_loss: 0.4850\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4858\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4342 - val_loss: 0.4779\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4837\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4334 - val_loss: 0.4804\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4288 - val_loss: 0.4878\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4703\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.4608\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.4738\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4229 - val_loss: 0.4630\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4171 - val_loss: 0.4568\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4270 - val_loss: 0.4655\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4193 - val_loss: 0.4538\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4556\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.4529\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.4559\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4114 - val_loss: 0.4504\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4734\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.4468\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4449\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4588\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4464\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4385\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4392\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4376\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4380\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4343\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4512\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4327\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3969 - val_loss: 0.4357\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4297\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3953 - val_loss: 0.5034\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.4336\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.4320\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4411\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3965 - val_loss: 0.4382\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.4301\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.4280\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.4264\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4254\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4321\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4319\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4277\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.4258\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4255\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.4253\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.4292\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.4231\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.4656\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4229\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4242\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4301\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.4284\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4229\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.4222\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.4218\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.4199\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4032 - val_loss: 0.4268\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4193\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.4199\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4191\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3933 - val_loss: 0.4245\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.4207\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.4155\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4201\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.4168\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4156\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4174\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4117\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.4146\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4153\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4142\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.4182\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.4147\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.4104\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.4113\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.4125\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4104\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4157\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.4088\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4099\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.4168\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4094\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.4113\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4081\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.4060\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.4092\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4070\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.4096\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.4072\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3866\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1592 - val_loss: 0.7074\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.6047\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5408 - val_loss: 0.5590\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5056 - val_loss: 0.5353\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4866 - val_loss: 0.5226\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 0.5139\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4684 - val_loss: 0.5098\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4624 - val_loss: 0.5045\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4575 - val_loss: 0.4980\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.4957\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4506 - val_loss: 0.4906\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4476 - val_loss: 0.4901\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4862\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4821\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4805\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4364 - val_loss: 0.4828\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4752\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4337 - val_loss: 0.4716\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4720\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4668\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4701\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4746\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.4619\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4621\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.4576\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4659\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4584\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4544\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4556\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4539\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4144 - val_loss: 0.4540\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4127 - val_loss: 0.4516\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.4472\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4121 - val_loss: 0.4501\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4462\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.4459\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4080 - val_loss: 0.4440\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4079 - val_loss: 0.4471\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4054 - val_loss: 0.4501\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4457\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4055 - val_loss: 0.4412\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4045 - val_loss: 0.4449\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.4419\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4385\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4362\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4422\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4359\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4007 - val_loss: 0.4365\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4002 - val_loss: 0.4368\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3998 - val_loss: 0.4365\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4321\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4413\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.4309\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4304\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3964 - val_loss: 0.4279\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4319\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.4295\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3947 - val_loss: 0.4259\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4249\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4259\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.4245\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.4253\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.4217\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.4298\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3919 - val_loss: 0.4221\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4210\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4200\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4178\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4235\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4152\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4205\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.4142\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.4178\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4127\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.4123\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4171\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4104\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4106\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4078\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.4077\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.4054\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4114\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.4030\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4052\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4118\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4061\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4012\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4063\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4081\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4025\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.4004\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4076\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3965\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3719 - val_loss: 0.4019\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.4052\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.3951\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4049\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4006\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.3973\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.3933\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3745\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0548 - val_loss: 0.9011\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6323 - val_loss: 0.6348\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5449 - val_loss: 0.5820\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5279 - val_loss: 0.5613\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.5501\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4867 - val_loss: 0.5620\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4692 - val_loss: 0.5688\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4569 - val_loss: 0.5755\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.5891\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4387 - val_loss: 0.6190\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4330 - val_loss: 0.6260\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4274 - val_loss: 0.6532\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4233 - val_loss: 0.6716\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.6976\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.7291\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4088\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9959 - val_loss: 0.6482\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6094 - val_loss: 0.5810\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.5437\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.5257\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4775 - val_loss: 0.5044\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4541 - val_loss: 0.5208\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4436 - val_loss: 0.4918\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.5011\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.4809\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.5353\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.4703\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4187 - val_loss: 0.4739\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4641\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4606\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4129 - val_loss: 0.4617\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4117 - val_loss: 0.4558\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4104 - val_loss: 0.4572\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4164 - val_loss: 0.4570\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4564\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4695\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4467\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4419\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4468\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4415\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4378\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4463\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.4329\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4326\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4336\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4417\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.4315\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.4261\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.4311\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.4302\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.4238\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4252\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4265\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.4227\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4289\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.4209\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4248\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.4199\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4428\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.4327\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4144\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.4414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.4232\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.4317\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4131\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4151\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.4114\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4105\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.4073\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.4102\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.5727\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.4062\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3682 - val_loss: 0.4099\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4148\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.4054\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.4115\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3680 - val_loss: 0.4078\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.4046\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.4019\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.8500\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.5244\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4665 - val_loss: 0.4120\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3810 - val_loss: 0.4034\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.4117\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.4075\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.4130\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.4017\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.4032\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3688 - val_loss: 0.3961\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4059\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.4130\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3983\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3998\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.6468\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.3953\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3930\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.4005\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3961\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3902\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3919\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3999\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3925\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3901\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.7993\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.3956\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5719 - val_loss: 0.4118\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4221\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.4036\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.3965\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3544 - val_loss: 0.3968\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3945\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3942\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3553 - val_loss: 0.3917\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3656\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6194 - val_loss: 1.1863\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7624 - val_loss: 0.5938\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5331 - val_loss: 0.5448\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4918 - val_loss: 0.5216\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4731 - val_loss: 0.5115\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4623 - val_loss: 0.5033\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4961\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4487 - val_loss: 0.4940\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4921\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4873\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 0.4830\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.4791\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4316 - val_loss: 0.4784\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.4714\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4701\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4230 - val_loss: 0.4665\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4642\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4162 - val_loss: 0.4573\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4131 - val_loss: 0.4600\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.4561\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4477\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4452\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4412\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4446\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3995 - val_loss: 0.4421\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4362\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4381\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4334\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4314\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4295\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.4239\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4215\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4190\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.4236\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4248\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4177\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.4201\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4201\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4113\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.4169\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.4123\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4108\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4107\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.4059\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.4061\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3680 - val_loss: 0.4095\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.4111\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.4022\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.4086\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.4029\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.4008\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3962\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3984\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3612 - val_loss: 0.3955\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3597 - val_loss: 0.3975\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3960\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3990\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.3931\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3883\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.3948\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3922\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3884\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3885\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3871\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3872\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.3884\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3862\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3823\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3843\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3795\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3815\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3780\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3774\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3789\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3792\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3805\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.3816\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.3791\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3800\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3829\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3782\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3785\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.3777\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3406\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7739 - val_loss: 0.5433\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4521 - val_loss: 0.4880\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.4537\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4380\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.4163\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4071\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4002\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.3828\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.3738\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.3920\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3429 - val_loss: 0.3726\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3335 - val_loss: 0.3715\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3645\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3251 - val_loss: 0.3590\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3447\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3160 - val_loss: 0.3562\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3523\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3111 - val_loss: 0.3356\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3072 - val_loss: 0.3493\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3065 - val_loss: 0.3445\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3039 - val_loss: 0.3541\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3028 - val_loss: 0.3316\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2999 - val_loss: 0.3338\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2986 - val_loss: 0.3346\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.3207\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2992 - val_loss: 0.3156\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2942 - val_loss: 0.3211\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3458\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2920 - val_loss: 0.3615\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2883 - val_loss: 0.3310\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2879 - val_loss: 0.3211\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2879 - val_loss: 0.3182\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3057 - val_loss: 0.3606\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.3140\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.3093\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.3698\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2843 - val_loss: 0.3115\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.3159\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.3071\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.3288\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.3053\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2780 - val_loss: 0.3171\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2787 - val_loss: 0.3270\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2771 - val_loss: 0.3130\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2756 - val_loss: 0.3375\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2759 - val_loss: 0.3043\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3166\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2759 - val_loss: 0.3060\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2744 - val_loss: 0.3041\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.3083\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.2944\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2733 - val_loss: 0.3015\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2720 - val_loss: 0.3124\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2699 - val_loss: 0.3029\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2699 - val_loss: 0.3072\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2702 - val_loss: 0.3103\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2706 - val_loss: 0.3120\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2686 - val_loss: 0.2985\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2675 - val_loss: 0.2918\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2672 - val_loss: 0.3097\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2670 - val_loss: 0.3066\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2665 - val_loss: 0.3046\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2670 - val_loss: 0.3048\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2648 - val_loss: 0.3546\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.2982\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2627 - val_loss: 0.3220\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2654 - val_loss: 0.3025\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2631 - val_loss: 0.2958\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.3062\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024ED63FB040&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x0000024ED6651B80&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024ED63FB040&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x0000024ED6651B80&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024ED63FB040&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024ED63FB040&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024ED63FB040>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000024ED6651B80>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008453461204835444, 'n_hidden': 3, 'n_neurons': 58}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3567943871021271"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68756eb6c044f31c46e3e1f38723aea1f0146198488dd3d60c0e4241eb6f7dd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
