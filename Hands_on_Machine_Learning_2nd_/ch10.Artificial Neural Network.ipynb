{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10. 케라스를 사용한 인공 신경망 소개"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 생물학적 뉴런에서 인공 뉴런까지"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # 꽃잎의 길이와 너비\n",
    "y = (iris.target == 0).astype(np.int) # 부채붓꽃(Iris Setosa)인가?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 케라스로 다층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.keras 에서 구현된 케라스 API 버젼 -tf 접미사는 tf.keras가 텐서플로 특화된 기능이 추가되어 케라스 API를 구현했다는 것을 나타냄\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스를 사용해 데이터셋 적재하기\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib.pyplot 의 imshow() 함수와 'binary' 컬러맵을 사용해 이미지 출력  가능\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~9 까지 클래스 아이디\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 이미지는 코트\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀셜 API를 사용해 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x24e8440bcd0>,\n",
       " <keras.layers.core.dense.Dense at 0x24e8440b2e0>,\n",
       " <keras.layers.core.dense.Dense at 0x24ed2082d60>,\n",
       " <keras.layers.core.dense.Dense at 0x24ec5f8a7f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_1 = model.layers[1]\n",
    "hidden_1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00900263,  0.04272863, -0.04711238, ..., -0.05374917,\n",
       "        -0.00437523, -0.04172974],\n",
       "       [-0.00654906,  0.01875776, -0.06586118, ...,  0.04730989,\n",
       "        -0.05571219,  0.0548614 ],\n",
       "       [ 0.04404957,  0.03006719,  0.06051371, ..., -0.01007503,\n",
       "         0.01528049, -0.06216595],\n",
       "       ...,\n",
       "       [ 0.03087259,  0.01648729, -0.06382301, ...,  0.04749279,\n",
       "        -0.06610171,  0.02856842],\n",
       "       [-0.00807952,  0.05528942, -0.02437977, ...,  0.01897026,\n",
       "         0.03872108,  0.06538887],\n",
       "       [-0.01073142,  0.06068146, -0.04091919, ...,  0.04069037,\n",
       "         0.04296832, -0.04729627]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden_1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "            optimizer = 'sgd',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.7238 - accuracy: 0.7623 - val_loss: 0.5201 - val_accuracy: 0.8270\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4897 - accuracy: 0.8292 - val_loss: 0.4711 - val_accuracy: 0.8332\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4463 - accuracy: 0.8425 - val_loss: 0.4339 - val_accuracy: 0.8558\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4183 - accuracy: 0.8519 - val_loss: 0.4272 - val_accuracy: 0.8584\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3975 - accuracy: 0.8607 - val_loss: 0.4102 - val_accuracy: 0.8542\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3835 - accuracy: 0.8642 - val_loss: 0.3703 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3687 - accuracy: 0.8693 - val_loss: 0.3816 - val_accuracy: 0.8652\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3579 - accuracy: 0.8722 - val_loss: 0.3573 - val_accuracy: 0.8772\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3465 - accuracy: 0.8773 - val_loss: 0.3543 - val_accuracy: 0.8714\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3363 - accuracy: 0.8787 - val_loss: 0.3607 - val_accuracy: 0.8674\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3286 - accuracy: 0.8829 - val_loss: 0.3615 - val_accuracy: 0.8694\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8854 - val_loss: 0.3325 - val_accuracy: 0.8778\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3127 - accuracy: 0.8878 - val_loss: 0.3375 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8907 - val_loss: 0.3286 - val_accuracy: 0.8800\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2984 - accuracy: 0.8914 - val_loss: 0.3235 - val_accuracy: 0.8814\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8943 - val_loss: 0.3495 - val_accuracy: 0.8756\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2867 - accuracy: 0.8967 - val_loss: 0.3217 - val_accuracy: 0.8820\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2795 - accuracy: 0.8997 - val_loss: 0.3344 - val_accuracy: 0.8816\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2761 - accuracy: 0.9001 - val_loss: 0.3207 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2713 - accuracy: 0.9029 - val_loss: 0.3116 - val_accuracy: 0.8868\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2657 - accuracy: 0.9036 - val_loss: 0.3229 - val_accuracy: 0.8826\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2601 - accuracy: 0.9064 - val_loss: 0.3093 - val_accuracy: 0.8858\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2569 - accuracy: 0.9071 - val_loss: 0.3053 - val_accuracy: 0.8884\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2517 - accuracy: 0.9092 - val_loss: 0.3031 - val_accuracy: 0.8918\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2484 - accuracy: 0.9103 - val_loss: 0.3018 - val_accuracy: 0.8892\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2430 - accuracy: 0.9127 - val_loss: 0.3372 - val_accuracy: 0.8792\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2405 - accuracy: 0.9136 - val_loss: 0.2975 - val_accuracy: 0.8926\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2355 - accuracy: 0.9151 - val_loss: 0.3042 - val_accuracy: 0.8910\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2311 - accuracy: 0.9163 - val_loss: 0.3003 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2282 - accuracy: 0.9180 - val_loss: 0.3015 - val_accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # 수직축 범위를 [0-1] 사이로 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3328465521335602, 0.881600022315979]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 예측한 정답\n",
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[np.argmax(y_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 정답\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀셜 API를 사용해 회귀용 다층 퍼셉트론 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9844 - val_loss: 0.8635\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5919 - val_loss: 0.5399\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4757 - val_loss: 0.5138\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 0.4949\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4665 - val_loss: 0.4840\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4708\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4245 - val_loss: 0.4899\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4176 - val_loss: 0.4568\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4115 - val_loss: 0.4522\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4484\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.4382\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4352\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4364\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4250\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4234\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4159\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.4218\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.4137\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.4094\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.4062\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3812\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # 새로운 샘플\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수형 API\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "# Sequential API\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#    keras.layers.Dense(300, activation='relu'),\n",
    "#    keras.layers.Dense(100, activation='relu'),\n",
    "#    keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30)           930         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 입력 다루기\n",
    "\n",
    "# 특성 0에서 4까지 5개의 특성을 와이드 경로에 보내고\n",
    "# 특성 2에서 7까지 6개의 특성을 딥 경로로 전달, 3개의 특성 (특성 2, 3, 4)는 양쪽에 모두 전달 됨\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.4818 - val_loss: 1.1341\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8815 - val_loss: 0.8086\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 0.7341\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6659 - val_loss: 0.6946\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6330 - val_loss: 0.6673\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6090 - val_loss: 0.6474\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5903 - val_loss: 0.6304\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5746 - val_loss: 0.6161\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5620 - val_loss: 0.6052\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5511 - val_loss: 0.5957\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5416 - val_loss: 0.5870\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5335 - val_loss: 0.5801\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.5759\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5682\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 0.5623\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5096 - val_loss: 0.5590\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5051 - val_loss: 0.5568\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 0.5509\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4974 - val_loss: 0.5488\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.5438\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5031\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제를 위한 보조 출력 추가하기\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 2.5238 - main_output_loss: 2.3991 - aux_output_loss: 3.6461 - val_loss: 1.2832 - val_main_output_loss: 1.0918 - val_aux_output_loss: 3.0055\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0219 - main_output_loss: 0.8601 - aux_output_loss: 2.4784 - val_loss: 0.9622 - val_main_output_loss: 0.8160 - val_aux_output_loss: 2.2779\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8405 - main_output_loss: 0.7154 - aux_output_loss: 1.9665 - val_loss: 0.8491 - val_main_output_loss: 0.7338 - val_aux_output_loss: 1.8865\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7621 - main_output_loss: 0.6603 - aux_output_loss: 1.6777 - val_loss: 0.7949 - val_main_output_loss: 0.6989 - val_aux_output_loss: 1.6588\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7169 - main_output_loss: 0.6295 - aux_output_loss: 1.5043 - val_loss: 0.7583 - val_main_output_loss: 0.6744 - val_aux_output_loss: 1.5131\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6871 - main_output_loss: 0.6083 - aux_output_loss: 1.3969 - val_loss: 0.7380 - val_main_output_loss: 0.6618 - val_aux_output_loss: 1.4236\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6647 - main_output_loss: 0.5915 - aux_output_loss: 1.3234 - val_loss: 0.7140 - val_main_output_loss: 0.6422 - val_aux_output_loss: 1.3599\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6475 - main_output_loss: 0.5786 - aux_output_loss: 1.2682 - val_loss: 0.6974 - val_main_output_loss: 0.6291 - val_aux_output_loss: 1.3123\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6332 - main_output_loss: 0.5674 - aux_output_loss: 1.2252 - val_loss: 0.6859 - val_main_output_loss: 0.6205 - val_aux_output_loss: 1.2742\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6205 - main_output_loss: 0.5574 - aux_output_loss: 1.1891 - val_loss: 0.6763 - val_main_output_loss: 0.6133 - val_aux_output_loss: 1.2436\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6098 - main_output_loss: 0.5489 - aux_output_loss: 1.1580 - val_loss: 0.6646 - val_main_output_loss: 0.6036 - val_aux_output_loss: 1.2132\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5994 - main_output_loss: 0.5404 - aux_output_loss: 1.1305 - val_loss: 0.6533 - val_main_output_loss: 0.5939 - val_aux_output_loss: 1.1879\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5911 - main_output_loss: 0.5339 - aux_output_loss: 1.1054 - val_loss: 0.6473 - val_main_output_loss: 0.5897 - val_aux_output_loss: 1.1653\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5830 - main_output_loss: 0.5275 - aux_output_loss: 1.0826 - val_loss: 0.6383 - val_main_output_loss: 0.5823 - val_aux_output_loss: 1.1428\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5757 - main_output_loss: 0.5218 - aux_output_loss: 1.0609 - val_loss: 0.6315 - val_main_output_loss: 0.5771 - val_aux_output_loss: 1.1209\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5687 - main_output_loss: 0.5162 - aux_output_loss: 1.0405 - val_loss: 0.6255 - val_main_output_loss: 0.5724 - val_aux_output_loss: 1.1028\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5623 - main_output_loss: 0.5113 - aux_output_loss: 1.0214 - val_loss: 0.6190 - val_main_output_loss: 0.5671 - val_aux_output_loss: 1.0857\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5566 - main_output_loss: 0.5070 - aux_output_loss: 1.0031 - val_loss: 0.6123 - val_main_output_loss: 0.5617 - val_aux_output_loss: 1.0675\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5510 - main_output_loss: 0.5027 - aux_output_loss: 0.9854 - val_loss: 0.6102 - val_main_output_loss: 0.5613 - val_aux_output_loss: 1.0502\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5460 - main_output_loss: 0.4990 - aux_output_loss: 0.9689 - val_loss: 0.6058 - val_main_output_loss: 0.5581 - val_aux_output_loss: 1.0345\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5549 - main_output_loss: 0.5077 - aux_output_loss: 0.9802\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # 표준 매개변수를 처리함 (예를 들어, name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 3.3682 - output_1_loss: 3.0897 - output_2_loss: 5.8746 - val_loss: 1.9422 - val_output_1_loss: 1.5068 - val_output_2_loss: 5.8610\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3370 - output_1_loss: 0.9428 - output_2_loss: 4.8851 - val_loss: 1.2022 - val_output_1_loss: 0.8431 - val_output_2_loss: 4.4346\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0281 - output_1_loss: 0.7344 - output_2_loss: 3.6720 - val_loss: 1.0103 - val_output_1_loss: 0.7509 - val_output_2_loss: 3.3442\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8938 - output_1_loss: 0.6807 - output_2_loss: 2.8125 - val_loss: 0.9048 - val_output_1_loss: 0.7134 - val_output_2_loss: 2.6274\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8031 - output_1_loss: 0.6418 - output_2_loss: 2.2549 - val_loss: 0.8286 - val_output_1_loss: 0.6793 - val_output_2_loss: 2.1721\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7413 - output_1_loss: 0.6125 - output_2_loss: 1.9007 - val_loss: 0.7730 - val_output_1_loss: 0.6499 - val_output_2_loss: 1.8803\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6963 - output_1_loss: 0.5878 - output_2_loss: 1.6730 - val_loss: 0.7318 - val_output_1_loss: 0.6259 - val_output_2_loss: 1.6848\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6636 - output_1_loss: 0.5684 - output_2_loss: 1.5208 - val_loss: 0.7041 - val_output_1_loss: 0.6093 - val_output_2_loss: 1.5568\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6383 - output_1_loss: 0.5515 - output_2_loss: 1.4197 - val_loss: 0.6818 - val_output_1_loss: 0.5949 - val_output_2_loss: 1.4645\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6186 - output_1_loss: 0.5377 - output_2_loss: 1.3466 - val_loss: 0.6649 - val_output_1_loss: 0.5835 - val_output_2_loss: 1.3973\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.6187 - output_1_loss: 0.5427 - output_2_loss: 1.3027\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024ED20ABB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2236 - val_loss: 1.1525\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8500 - val_loss: 0.7467\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6691 - val_loss: 0.6826\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6219 - val_loss: 0.6469\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5897 - val_loss: 0.6171\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5654 - val_loss: 0.5986\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5833\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5676\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 0.5550\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5028 - val_loss: 0.5474\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5021\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./keras/my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"./keras/my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024E89951D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.601483 ],\n",
       "       [1.8697193],\n",
       "       [3.9253507]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24ed95282e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"./keras/my_keras_weights.ckpt\")\n",
    "model.load_weights(\"./keras/my_keras_weights.ckpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1715 - val_loss: 1.0318\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7715 - val_loss: 0.7183\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6238 - val_loss: 0.6384\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5748 - val_loss: 0.6050\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5463 - val_loss: 0.5799\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5278 - val_loss: 0.5656\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5128 - val_loss: 0.5529\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 0.5442\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 0.5371\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4877 - val_loss: 0.5322\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4883\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./keras/my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"./keras/my_keras_model.h5\") # 최상의 모델로 롤백\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4805 - val_loss: 0.5274\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4765 - val_loss: 0.5216\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.5207\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4674 - val_loss: 0.5153\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4643 - val_loss: 0.5162\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.5114\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4584 - val_loss: 0.5080\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.5081\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.5046\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.5046\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4475 - val_loss: 0.5004\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4452 - val_loss: 0.4979\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4988\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4948\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.4918\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4914\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4355 - val_loss: 0.4884\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4884\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4859\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4835\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4821\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4807\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4790\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4256 - val_loss: 0.4778\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4776\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.4748\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4220 - val_loss: 0.4737\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4728\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4193 - val_loss: 0.4726\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4711\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4691\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4681\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4665\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4133 - val_loss: 0.4653\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4644\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4623\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4638\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4610\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.4593\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4593\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.4561\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.4569\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4036 - val_loss: 0.4552\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4026 - val_loss: 0.4539\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4017 - val_loss: 0.4523\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.4522\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3997 - val_loss: 0.4502\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4498\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4476\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.4487\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3962 - val_loss: 0.4461\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4457\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3940 - val_loss: 0.4437\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4428\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4421\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4419\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.4410\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4399\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4388\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4375\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.4374\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4360\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4345\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4341\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4336\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4316\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4314\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4299\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.4293\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4311\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4270\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4276\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4247\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4243\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.4231\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4225\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4225\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4206\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4210\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4193\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4190\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.4191\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4162\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.4171\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.4149\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.4156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.4144\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.4130\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3662 - val_loss: 0.4117\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.4132\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.4112\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.4099\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.4087\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4081\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.4094\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.4078\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.4063\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.4053\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.4048\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.4043\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3707\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/363 [===========================>..] - ETA: 0s - loss: 0.3601\n",
      "val/train: 1.12\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.4033\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서보드(TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_01_31-17_39_24'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7606 - val_loss: 0.8938\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7660 - val_loss: 0.7384\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6771 - val_loss: 0.6912\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6384 - val_loss: 0.6614\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6108 - val_loss: 0.6415\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5884 - val_loss: 0.6215\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5693 - val_loss: 0.6035\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5532 - val_loss: 0.5900\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 0.5783\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.5673\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.5597\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5068 - val_loss: 0.5501\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4983 - val_loss: 0.5431\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5357\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4830 - val_loss: 0.5306\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4760 - val_loss: 0.5238\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.5190\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5130\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4599 - val_loss: 0.5088\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4542 - val_loss: 0.5046\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.5007\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4972\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4941\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 0.4899\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4865\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4834\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4292 - val_loss: 0.4822\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4789\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4762\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4220 - val_loss: 0.4756\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard 실행  \n",
    "- 텐서보드 설치된 가상환경 활성화\n",
    "- 노트북 디렉토리로 이동하여 다음 명령 입력\n",
    "- tensorboard --logdir=./my_logs --port=6006  \n",
    "\n",
    "그다음 웹 브라우저를 열고 localhost:6006에 접속하면 텐서보드를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # 몇몇 랜덤 데이터\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # 32 * 32 RGB 이미지\n",
    "        tf.summary.image('my_images', images * step / 1000, step=step)\n",
    "        texts = [\"The step is\" + str(step), \"Its square is\", str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000)/48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 신경망 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1364 - val_loss: 0.7597\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6791 - val_loss: 0.6618\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5883 - val_loss: 0.5950\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.5590\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4984 - val_loss: 0.5296\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.5128\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5029\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 0.4979\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4898\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4893\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4380 - val_loss: 0.4814\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4804\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4813\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4249 - val_loss: 0.4714\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4231 - val_loss: 0.4702\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4686\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4164 - val_loss: 0.4645\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.4609\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.4582\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4591\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4550\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4536\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4545\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4473\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 0.4496\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4612\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4427\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4401\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4405\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4373\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.4350\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.4350\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.4324\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4354\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.4310\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.4301\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.4298\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.4273\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.4283\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4242\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.4255\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4224\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.4250\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.4190\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4201\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.4197\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.4187\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.4257\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.4163\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3673 - val_loss: 0.4219\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.4142\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.4116\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.4140\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.4115\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.4157\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.4089\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.4089\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.4097\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.4087\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.4094\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.4065\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.4046\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.4041\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.4068\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.4022\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.4097\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.4045\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.4035\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.4001\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.4014\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3998\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3983\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3994\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.4176\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3956\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3980\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3922\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.4012\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3953\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3936\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3906\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.4057\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.4023\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3892\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3897\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3861\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3972\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3935\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3873\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3845\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.3853\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3869\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.3961\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.3873\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3845\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3843\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3857\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3835\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3900\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3614\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "            validation_data = (X_valid, y_valid),\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68756eb6c044f31c46e3e1f38723aea1f0146198488dd3d60c0e4241eb6f7dd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
